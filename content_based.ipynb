{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Content Based Recommender System\n",
    "The goal of this recommender is to look at tracks (in a playlist) and recommend similar new tracks, by only comparing what features the tracks in the user's playlist has compared to tracks from the dataset we use.\n",
    "\n",
    "For playlists we choose a previously explored playlist from the Spotify million playlist dataset[0].\n",
    "\n",
    "For track features we use a dataset from *kaggle*[1] that was recommended through a tutorial by *Tanmoy Ghosh*[2] we leaned heavily on along with insights from *Data Science from Scratch, 2nd Edition by Joel Grus*[3]\n",
    "\n",
    "[0]https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\n",
    "\n",
    "[1]https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db\n",
    "\n",
    "[2]https://www.section.io/engineering-education/building-spotify-recommendation-engine/#implementation\n",
    "\n",
    "[3]https://www.oreilly.com/library/view/data-science-from/9781492041122/\n",
    "\n",
    "## Datasets\n",
    "### kaggle - SpotifyFeatures.csv\n",
    "\n",
    "A .csv document with 26 genres and a total of 232,725 tracks with the following features:\n",
    "\n",
    "| genre | artist_name    | track_name                  | track_id               | popularity | acousticness | danceability | duration_ms | energy | instrumentalness | key | liveness | loudness | mode  | speechiness | tempo   | time_signature | valence |\n",
    "|-------|----------------|-----------------------------|------------------------|------------|--------------|--------------|-------------|--------|------------------|-----|----------|----------|-------|-------------|---------|----------------|---------|\n",
    "| Movie | Henri Salvador | C'est beau de faire un Show | 0BRjO6ga9RKCKjfDqeFgWV | 0          | 0.611        | 0.389        | 99373       | 0.91   | 0                | C#  | 0.346    | -1.828   | Major | 0.0525      | 166.969 | 04-Apr         | 0.814   |\n",
    "\n",
    "### Spotify MPD - playlists.json\n",
    "Json data used in other recommenders and exploration. For future elaboration, please see the explanation in the collaborative_based notebook.\n",
    "\n",
    "## Content Based Filters\n",
    "*Unlike collaborative methods that only rely on the user-item interactions, content-based approaches use additional information about users and/or items. They rely on the assumption that items with similar properties and features will be rated similarly. Determining which features and attributes are most predictive for a given user is the challenge.*\n",
    "\n",
    "As we have our goals set already, Spotify recommendation and a dataset picked out for us we can easily pull from them to explain. As John Deer adds tracks to his playlist, we can draw a vector on all the features in his playlist, like tempo or danceability and then look for tracks with a close (a small of a difference as possible) cosine similarity as his playlist.\n",
    "\n",
    "The advantage of the content-based filter is that John Deer doesnâ€™t need to rely on others, a tracks features is simply raw data we gather from the track itself so even if John Deer was the first user in the world on Spotify, we could still recommend him tracks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlists and metadata\n",
    "We'll get the same playlists and metadata that we explored in the earlier notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "\n",
    "playlists = []\n",
    "DATA_PATH = \"mpd/data_samples\"\n",
    "REWRITE_DATA = True # Set to True to not use the stored pickled vectors \n",
    "\n",
    "num_files = len(os.listdir(DATA_PATH))\n",
    "\n",
    "# Load in every json file from the mpd/data_samples directory\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    with open(os.path.join(DATA_PATH, filename), \"rt\", encoding=\"utf-8\") as f:\n",
    "        playlists.extend(json.load(f)[\"playlists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_attribute(playlists, attribute):\n",
    "    '''\n",
    "        goes through dicts and appends value for choosen attribute\n",
    "        \n",
    "            playlist[] = list of dicts with playlist from million playlist dataset\n",
    "            attribute(string): 'track_name', 'album_name' or 'artist_name'\n",
    "            \n",
    "        returns a dict\n",
    "    '''\n",
    "    d = {}\n",
    "    s = attribute.split('_',)\n",
    "    if attribute == 'track_name':\n",
    "        for playlist in playlists:\n",
    "            for track in playlist['tracks']:\n",
    "                if track[attribute] not in d:\n",
    "                    d[track[attribute]] = {s[0]+'_popularity':1, 'artist_name':track['artist_name'], 'album_name':track['album_name']}\n",
    "                else:\n",
    "                    d[track[attribute]][s[0]+'_popularity'] += 1\n",
    "    else:\n",
    "        for playlist in playlists:\n",
    "            for track in playlist['tracks']:\n",
    "                if track[attribute] not in d:\n",
    "                    d[track[attribute]] = 1\n",
    "                else:\n",
    "                    d[track[attribute]] += 1\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dicts\n",
    "artists = get_top_attribute(playlists, 'artist_name')\n",
    "songs = get_top_attribute(playlists, 'track_name')\n",
    "albums = get_top_attribute(playlists, 'album_name')\n",
    "# make df from tracks\n",
    "metadata = pd.DataFrame.from_dict(songs, orient='index')\n",
    "# add album and artist scores\n",
    "metadata['artist_popularity']=metadata['artist_name'].apply(lambda x: artists.get(x,0))\n",
    "metadata['album_popularity']=metadata['album_name'].apply(lambda x: albums.get(x,0))\n",
    "# reformat the df to be more readable (in our opinion)\n",
    "metadata=metadata[['track_popularity', 'artist_name', 'artist_popularity', 'album_name', 'album_popularity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Spotify data\n",
    "We found a dataset on kaggle with sufficent track features that we will use to build a content based recommender system.\n",
    "This dataset has most of the key features we'd need to make content based decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "spotify_data = pd.read_csv('SpotifyFeatures.csv')\n",
    "# make a features dataframe\n",
    "spotify_features_df = spotify_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE - One-Hot Encoding\n",
    "    - Categorical data are variables that contain label values rather than numeric values.\n",
    "    - https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "    \n",
    "Since we can't use genres like Pop, Soul, Country or Track keys like C# or D into a numerical calculation we can turn them into numerical data using pandas.get_dummies and apply them later on as booelan columns in our feature dataframe.\n",
    "\n",
    "Trying to encode track, album or artist names seems less important than genre or key for content feature (and we simply did not have the computer capacity take any larger messures either)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre and keys with OHE\n",
    "genre_OHE = pd.get_dummies(spotify_features_df.genre)\n",
    "key_OHE = pd.get_dummies(spotify_features_df.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to fit all data\n",
    "scaled_features = MinMaxScaler().fit_transform([\n",
    "  spotify_features_df['acousticness'].values,\n",
    "  spotify_features_df['danceability'].values,\n",
    "  spotify_features_df['duration_ms'].values,\n",
    "  spotify_features_df['energy'].values,\n",
    "  spotify_features_df['instrumentalness'].values,\n",
    "  spotify_features_df['liveness'].values,\n",
    "  spotify_features_df['loudness'].values,\n",
    "  spotify_features_df['speechiness'].values,\n",
    "  spotify_features_df['tempo'].values,\n",
    "  spotify_features_df['valence'].values,\n",
    "  ])\n",
    "# put them into the feature dataframe\n",
    "spotify_features_df[['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence']] = scaled_features.T\n",
    "# Add the OHE data we made earlier\n",
    "spotify_features_df = spotify_features_df.join(genre_OHE)\n",
    "spotify_features_df = spotify_features_df.join(key_OHE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into metadata\n",
    "We can join the new features on as many tracks as possible in our metadata so that we have one large set with everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can join metadata and spotify_features on track_name\n",
    "metadata.index = metadata.index.set_names(['track_name'])\n",
    "# we don't want duouble columns thou, lets drop some redundant columns from the feature\n",
    "spotify_features_df = spotify_features_df.drop('artist_name', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(metadata, spotify_features_df, how='inner', on=['track_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, plenty of tracks get joined from multiple albums\n",
    "metadata = metadata.drop_duplicates(['track_name'])\n",
    "# remove old index and put a new one\n",
    "metadata = metadata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have merged the large metadata, lets make the spotify_features_df into purley features that we use in a recommender\n",
    "spotify_features_df = spotify_features_df.drop('genre',axis = 1)\n",
    "spotify_features_df = spotify_features_df.drop('track_name', axis = 1)\n",
    "spotify_features_df = spotify_features_df.drop('popularity',axis = 1)\n",
    "spotify_features_df = spotify_features_df.drop('key', axis = 1)\n",
    "spotify_features_df = spotify_features_df.drop('mode', axis = 1)\n",
    "spotify_features_df = spotify_features_df.drop('time_signature', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The user\n",
    "We can create a comprehensive user dataframe with all features from their playlist by merging with the metadata.\n",
    "\n",
    "As with our previous exploration we'll pick playlist **42** to keep things as decirnable as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the playlist dataframe with extended features using Spotify data\n",
    "def generate_user_features_df(user_playlist, spotify_data):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i, j in enumerate(user_playlist['tracks']):\n",
    "        df.loc[i, 'track_name'] = j['track_name']\n",
    "    \n",
    "    # merge features from metadata\n",
    "    df = pd.merge(df, metadata, how='inner', on=['track_name'])\n",
    "    # drop columns not used for making vectors (i.e not numeric)\n",
    "    df = df.drop(columns=['track_name', 'track_popularity', 'artist_name', 'artist_popularity', 'album_name', 'album_popularity'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_df = generate_user_features_df(playlists[42], metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non user songs\n",
    "Lets get the tracks not in our users playlists (we don't want to recommend tracks the user already has in their playlist afterall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_user_playlist(spotify_features, user_features):\n",
    "    # songs not in the users playlist\n",
    "    spotify_features_non_user_playlist = spotify_features[~spotify_features['track_id'].isin(user_features['track_id'].values)]\n",
    "    \n",
    "    return spotify_features_non_user_playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors\n",
    "We can summirize our users playlist into 1 nice vector that later will identify similar tracks from our non user tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_user_playlist_df = create_non_user_playlist(spotify_features_df, user_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist_vector(spotify_features, user_features):\n",
    "    \n",
    "    # make vectors for all songs\n",
    "    user_features_playlist = spotify_features[spotify_features['track_id'].isin(user_features['track_id'].values)]\n",
    "    \n",
    "\n",
    "    return user_features_playlist.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlist_vector = create_playlist_vector(spotify_features_df, user_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender\n",
    "Finally the recommender, comparing cosine_similarity for our vectors in different tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation(spotify_data, user_playlist_vector, non_user_playlist_df):\n",
    "    \n",
    "    # rather than making loads of copies to workaround a warning, we'll suppress this 1 warning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    # Make the not in user playlist\n",
    "    recommendations = spotify_data[spotify_data['track_id'].isin(non_user_playlist_df['track_id'].values)]\n",
    "    # combine all columns (but track_id) and check costine similarity between the users songs and songs not in the users playlist\n",
    "    recommendations['sim'] = cosine_similarity(non_user_playlist_df.drop(['track_id'], axis = 1).values, user_playlist_vector.drop(labels = 'track_id').values.reshape(1, -1))[:,0]\n",
    "    # sort the not in user playlist by cosine similariy\n",
    "    recommendations = recommendations.sort_values('sim',ascending = False)\n",
    "    \n",
    "    return  recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend = generate_recommendation(spotify_data, user_playlist_vector, non_user_playlist_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150461</th>\n",
       "      <td>Pop</td>\n",
       "      <td>BROCKHAMPTON</td>\n",
       "      <td>THUG LIFE</td>\n",
       "      <td>2c09gumRCmu3qmbcqdQbUN</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151833</th>\n",
       "      <td>Pop</td>\n",
       "      <td>JID</td>\n",
       "      <td>EdEddnEddy</td>\n",
       "      <td>4vmqU3xlzuhxtaeXrtAX1F</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150955</th>\n",
       "      <td>Pop</td>\n",
       "      <td>DaniLeigh</td>\n",
       "      <td>All I Know</td>\n",
       "      <td>4dxM44QcHvrbTqCtBsNprG</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112919</th>\n",
       "      <td>Pop</td>\n",
       "      <td>YBN Cordae</td>\n",
       "      <td>Target</td>\n",
       "      <td>13K3BqdOYYMepkNQPWL1DZ</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150818</th>\n",
       "      <td>Pop</td>\n",
       "      <td>Logic</td>\n",
       "      <td>State Of Emergency</td>\n",
       "      <td>58cvckETahSOG74RP5WE99</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>C</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       genre   artist_name          track_name                track_id  \\\n",
       "150461   Pop  BROCKHAMPTON           THUG LIFE  2c09gumRCmu3qmbcqdQbUN   \n",
       "151833   Pop           JID          EdEddnEddy  4vmqU3xlzuhxtaeXrtAX1F   \n",
       "150955   Pop     DaniLeigh          All I Know  4dxM44QcHvrbTqCtBsNprG   \n",
       "112919   Pop    YBN Cordae              Target  13K3BqdOYYMepkNQPWL1DZ   \n",
       "150818   Pop         Logic  State Of Emergency  58cvckETahSOG74RP5WE99   \n",
       "\n",
       "        popularity  acousticness  danceability  duration_ms    energy  \\\n",
       "150461          62      0.000053      0.000055          1.0  0.000056   \n",
       "151833          62      0.000071      0.000075          1.0  0.000073   \n",
       "150955          60      0.000050      0.000052          1.0  0.000054   \n",
       "112919          66      0.000049      0.000055          1.0  0.000054   \n",
       "150818          62      0.000050      0.000054          1.0  0.000054   \n",
       "\n",
       "        instrumentalness key  liveness  loudness   mode  speechiness  \\\n",
       "150461          0.000050   C  0.000051       0.0  Major     0.000051   \n",
       "151833          0.000070   C  0.000073       0.0  Major     0.000073   \n",
       "150955          0.000050   C  0.000052       0.0  Minor     0.000053   \n",
       "112919          0.000049   C  0.000050       0.0  Major     0.000052   \n",
       "150818          0.000049   C  0.000050       0.0  Major     0.000051   \n",
       "\n",
       "           tempo time_signature   valence       sim  \n",
       "150461  0.001351            4/4  0.000053  0.703883  \n",
       "151833  0.001194            4/4  0.000072  0.703883  \n",
       "150955  0.001196            4/4  0.000054  0.703883  \n",
       "112919  0.001189            4/4  0.000052  0.703883  \n",
       "150818  0.001176            4/4  0.000054  0.703883  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top reommendations for our user\n",
    "recommend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
