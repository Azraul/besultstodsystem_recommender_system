{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Collaborative Filtering\n",
    "The goal of this recommender is to look at a playlist and recommend similar new tracks, by only comparing what songs other users have added to their own playlists.\n",
    "Using just which songs exist in the playlists means the user doesn't have to give a score/like for every track in order to get recommendations, and neither does the recommender need it to produce valuable insights. Instead it is implied that a user adds a specific track to their playlist because they find the song good/compelling, and fitting for the playlist they are building.\n",
    "\n",
    "For data we use the Spotify million playlist dataset[0].\n",
    "\n",
    "Following the recommender systems chapter from *Data Science from Scratch, 2nd Edition by Joel Grus*[1], we have implemented a recommender which can do both user-based collaborative filtering (playlists with songs), and also item-based collaborative filtering (songs with playlists).\n",
    "\n",
    "[0]https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\n",
    "\n",
    "[1]https://www.oreilly.com/library/view/data-science-from/9781492041122/\n",
    "\n",
    "## Dataset\n",
    "A json or two of the Spotify million playlist dataset are used to supply data to the recommender.\n",
    "The MPD does not contain any auditory properties of the tracks, so the goal is to find correlations only based on what items the playlists contain.\n",
    "As seen in the exploratory notebook, the playlists come with a bunch of meta data such as number of tracks/albums/artists, the Spotify URI etc. \n",
    "\n",
    "A sample playlist looks like the following:\n",
    "```\n",
    "{\n",
    "            \"name\": \"TRVP\", \n",
    "            \"collaborative\": \"false\", \n",
    "            \"pid\": 26439, \n",
    "            \"modified_at\": 1505260800, \n",
    "            \"num_tracks\": 10, \n",
    "            \"num_albums\": 9, \n",
    "            \"num_followers\": 1, \n",
    "            \"tracks\": [\n",
    "                {\n",
    "                    \"pos\": 0, \n",
    "                    \"artist_name\": \"Sfera Ebbasta\", \n",
    "                    \"track_uri\": \"spotify:track:6Xq4v660hdyAwFiu9nXRlZ\", \n",
    "                    \"artist_uri\": \"spotify:artist:23TFHmajVfBtlRx5MXqgoz\", \n",
    "                    \"track_name\": \"Ciny\", \n",
    "                    \"album_uri\": \"spotify:album:6GIzEUMuSVY9TgdfZvzmBD\", \n",
    "                    \"duration_ms\": 166346, \n",
    "                    \"album_name\": \"XDVR Reloaded\"\n",
    "                }, \n",
    "                {\n",
    "                    \"pos\": 1, \n",
    "                    \"artist_name\": \"Sfera Ebbasta\", \n",
    "                    \"track_uri\": \"spotify:track:0QuQVxpCB1zd7xIBAcgjuR\", \n",
    "                    \"artist_uri\": \"spotify:artist:23TFHmajVfBtlRx5MXqgoz\", \n",
    "                    \"track_name\": \"XDVRMX\", \n",
    "                    \"album_uri\": \"spotify:album:6GIzEUMuSVY9TgdfZvzmBD\", \n",
    "                    \"duration_ms\": 202445, \n",
    "                    \"album_name\": \"XDVR Reloaded\"\n",
    "                }, \n",
    "                {\n",
    "                    \"pos\": 2, \n",
    "                    \"artist_name\": \"Sfera Ebbasta\", \n",
    "                    \"track_uri\": \"spotify:track:1S2VLr8j9KVbroLn76RF4i\", \n",
    "                    \"artist_uri\": \"spotify:artist:23TFHmajVfBtlRx5MXqgoz\", \n",
    "                    \"track_name\": \"Tran Tran\", \n",
    "                    \"album_uri\": \"spotify:album:6no7XEwjK8pAELt9aClXFx\", \n",
    "                    \"duration_ms\": 220968, \n",
    "                    \"album_name\": \"Tran Tran\"\n",
    "                }, \n",
    "                {\n",
    "                ...\n",
    "                },\n",
    "}\n",
    "```\n",
    "\n",
    "Only the playlist, artist and song name will be used. Artist+song name will be combined to be used for vectorization and the playlist name will be used to produce funny non-sensical name recommendations.\n",
    "\n",
    "One json contains 1000 playlists, and more than a couple files is too much for this library-less solution(except using numpys dot product for a bit more performance), since Python is a really slow data when it comes to processing large data unless it is calling C/native code functions in the background. The item-based recommender takes especially long with 2 jsons, 1 hour for a single run! 1 json takes ~3 minutes.\n",
    "\n",
    "\n",
    "## Assessment\n",
    "There's no assessment function, but from what we've interpreted of these implementations, it would be hard to assess because mostly the popular songs are recommended, so if we removed a few songs to see if they'd get re-recommended, they probably wouldn't if they were more niche tracks. So a \"qualitative\" method will be used instead.\n",
    "\n",
    "## Collaborative filters\n",
    "The recommender is based on the explanations and code in Joel Grus' book `Data Science from Scratch, 2nd Edition`. While the lecture material went through the user-based approach, we also delved deeper into the actual book and implemented an item-based approach the book is talking about.\n",
    "\n",
    "### User-based\n",
    "The user-based approach looks at what other users have added to their playlist and compares the supplied playlist/songs with those.\n",
    "Each playlist is transformed into a sparse feature vector, where the vector is `num_unique_songs` long and the respective positions represent a unique song. When *Jane Doe* adds her favourite country songs to her playlist, the playlist's vector is compared in similarity to all other existing vectors using cosine similarity. A lower value means the playlists are less similar. Then we go through each playlist’s tracks, assigning the track names to a big dictionary and += the songs with their own playlist's cosine similarity value.\n",
    "\n",
    "Similar playlists will give much more weight to their songs, and likewise very popular songs will gain a high score, even though these songs might be in very similar playlists. The end result is a list of songs with decent chance of being similar to Jane Doe's favourites.\n",
    "\n",
    "\n",
    "### Item-based\n",
    "The item-based approach is quite similar to user-based, with the big difference being the playlist vectors being turned around into a list of songs, its feature vector is a long list indicating which playlist the song exists in. The matrix is `num_unique_songsrows` x `num_playlists`. Jane Doe now has a sparse feature vector for each song in her playlist but is it still the same type of logic as a user-based, where the vectors get a cosine between each other, and these similarities are added up for the tracks to produce a ranking of most similar songs.\n",
    "\n",
    "The advantage of an item-based approach could perhaps be that if Jane adds a track of very different genre compared to what her usual listening, we can now compare the similarity of this one track to all others and get similar tracks (without having to compare her playlist as a whole).\n",
    "\n",
    "The advantage of an item-based approach could perhaps be that if John adds a track of very different genre compared to what his usual listening, we can now compare the similarity of this one track to all others and get similar tracks. (without having to compare his playlist as a whole)\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List, Tuple, Union\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Collaborative_Recommender:\n",
    "    Vector = List[int]\n",
    "\n",
    "    def __init__(self, path: str, rewrite_data: bool = False, playlist_limit: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        path: file path to the spotify jsons. Uses all jsons found.\n",
    "        rewrite_data: True = Always create new vectors based off the jsons, False = Try to use pickled\n",
    "            vectors, if not found generate new vectors and pickle them.\n",
    "        playlist_limit: Limit the number of playlists to use\n",
    "        \"\"\"\n",
    "        self.playlists = []\n",
    "        self.path = path\n",
    "        self.rewrite_data = rewrite_data\n",
    "        self.load_data(path, playlist_limit)\n",
    "        # Shuffle playlists as to reduce possible bias\n",
    "        random.shuffle(self.playlists)\n",
    "\n",
    "    def load_data(self, data_path: str, limit: int = 0):\n",
    "        try:\n",
    "            print(\"Loading the found jsons:\", os.listdir(data_path))\n",
    "            for filename in os.listdir(data_path):\n",
    "                with open(os.path.join(data_path, filename), \"rt\", encoding=\"utf-8\") as f:\n",
    "                    self.playlists.extend(json.load(f)[\"playlists\"])\n",
    "            print(f\"Loaded {len(os.listdir(data_path))} jsons\")\n",
    "\n",
    "            if limit > 0:\n",
    "                self.playlists = self.playlists[:limit]\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"File not found:\", e)\n",
    "\n",
    "    def extract_unique_songs(self):\n",
    "        \"\"\"Puts all unique songs from the playlist into an array\"\"\"\n",
    "        self.unique_songs = sorted(\n",
    "            {\n",
    "                f\"{song['artist_name']} - {song['track_name']}\"\n",
    "                for playlist in self.playlists\n",
    "                for i, song in enumerate(playlist[\"tracks\"])\n",
    "            }\n",
    "        )\n",
    "        print(f\"Found {len(self.unique_songs)} unique songs\")\n",
    "\n",
    "    def extract_playlist_names(self):\n",
    "        \"\"\"Puts all playlists' names into an array with the same order as the playlists\"\"\"\n",
    "        self.playlist_names = [playlist[\"name\"] for playlist in self.playlists]\n",
    "\n",
    "    def sample_tracks(self, pos: int, num: int):\n",
    "        for s in self.playlists[pos][\"tracks\"][:num]:\n",
    "            print(f\"{s['artist_name']} - {s['track_name']}\")\n",
    "\n",
    "    def to_track_names(self, playlists) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Compiles every track in every playlist an '<artist> - <song>' name, into an array of the\n",
    "        same shape as the playlists\n",
    "        \"\"\"\n",
    "        return [\n",
    "            [f\"{s['artist_name']} - {s['track_name']}\" for i, s in enumerate(playlist[\"tracks\"])]\n",
    "            for playlist in playlists\n",
    "        ]\n",
    "\n",
    "    def make_playlist_vector(self, playlist: Union[dict, List[str]]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Given a list of playlists, produce a vector whose ith element is 1\n",
    "        if unique_songs[i] is in the list, 0 otherwise\n",
    "        \"\"\"\n",
    "        playlist_ = []\n",
    "        # Checks if the functiun gets called from multiprocessing\n",
    "        if isinstance(playlist, tuple):\n",
    "            _, playlist_ = playlist\n",
    "        else:\n",
    "            playlist_ = playlist\n",
    "        # Checking whether it's a dict or list, since one can supply a list of song names too\n",
    "        if isinstance(playlist_, dict):\n",
    "            return [\n",
    "                1\n",
    "                if song in [f\"{s['artist_name']} - {s['track_name']}\" for s in playlist_[\"tracks\"]]\n",
    "                else 0\n",
    "                for song in self.unique_songs\n",
    "            ]\n",
    "        elif isinstance(playlist_, List):\n",
    "            return [1 if song in playlist_ else 0 for song in self.unique_songs]\n",
    "\n",
    "    def make_user_based_vectors(self):\n",
    "        \"\"\"\n",
    "        Generates sparse feature vectors of the given playlists\n",
    "        Assigns 1 to n'th position if the playlist includes song n, else 0\n",
    "        Uses multiprocessing to speed up the generation\n",
    "        Pickles the vectors so they dont have to be recalculated on a rerun\n",
    "        \"\"\"\n",
    "        import multiprocessing as mp\n",
    "\n",
    "        # Using multiprocessing to speed up the vector creation\n",
    "        # Spawns a new python process to run the make_playlist_vector method\n",
    "        p = mp.Pool(14)  # 14 available processes, dunno if this works badly on <16 cpu threads\n",
    "        t0 = time.time()\n",
    "\n",
    "        try:\n",
    "            if self.rewrite_data:\n",
    "                print(\"Rewriting data: Generating vectors and dumping them\")\n",
    "                self.extract_unique_songs()\n",
    "                self.playlist_vectors = p.map(self.make_playlist_vector, enumerate(self.playlists))\n",
    "                vector_file = open(\"playlist_vectors.pickle\", \"wb\")\n",
    "                playlist_file = open(\"playlists.pickle\", \"wb\")\n",
    "                print(\"Pickling...\")\n",
    "                pickle.dump(self.playlist_vectors, vector_file)\n",
    "                pickle.dump(self.playlists, playlist_file)\n",
    "            else:\n",
    "                vector_file = open(\"playlist_vectors.pickle\", \"rb\")\n",
    "                playlist_file = open(\"playlists.pickle\", \"rb\")\n",
    "\n",
    "                print(\"Pickled data found.\")\n",
    "                self.playlist_vectors = pickle.load(vector_file)\n",
    "                self.playlists = pickle.load(playlist_file)\n",
    "                self.extract_unique_songs()\n",
    "        except (FileNotFoundError):\n",
    "            print(\"Pickled data not found, generating vectors...\")\n",
    "            self.extract_unique_songs()\n",
    "            self.playlist_vectors = p.map(self.make_playlist_vector, enumerate(self.playlists))\n",
    "            vector_file = open(\"playlist_vectors.pickle\", \"wb\")\n",
    "            playlist_file = open(\"playlists.pickle\", \"wb\")\n",
    "            print(\"Pickling...\")\n",
    "            pickle.dump(self.playlist_vectors, vector_file)\n",
    "            pickle.dump(self.playlists, playlist_file)\n",
    "        finally:\n",
    "            vector_file.close()\n",
    "            playlist_file.close()\n",
    "            self.named_playlists = self.to_track_names(self.playlists)\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(f\"Time taken: {round(t1-t0, 2)} s\")\n",
    "        print(\"playlist_vectors length:\", len(self.playlist_vectors))\n",
    "\n",
    "    def make_item_based_vectors(self):\n",
    "        \"\"\"\n",
    "        Flips the playlist-songs matrix into songs-playlists\n",
    "        So that each row is a song, and the sparse vector tells which playlist this song is in\n",
    "        \"\"\"\n",
    "        self.song_playlist_matrix: List[List[int]] = [\n",
    "            [playlist_vector[i] for playlist_vector in self.playlist_vectors]\n",
    "            for i, _ in enumerate(self.unique_songs)\n",
    "        ]\n",
    "\n",
    "    def cosine_similarity(self, v1: Vector, v2: Vector) -> float:\n",
    "        \"\"\"Calculates the cosine between two feature vectors\"\"\"\n",
    "        return np.dot(v1, v2) / math.sqrt(np.dot(v1, v1) * np.dot(v2, v2))\n",
    "\n",
    "    def compute_similarities(self, pv) -> List[float]:\n",
    "        \"\"\"Runs cosine_similarity on each playlist_vector\"\"\"\n",
    "        return [self.cosine_similarity(pv, pv_i) for pv_i in self.playlist_vectors]\n",
    "\n",
    "    def sort_similar_playlists(\n",
    "        self, similarities: List[float], user_id: int\n",
    "    ) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        Create a sorted list of the similar playlists.\n",
    "        Each element is a tuple of the playlist's id and its cosine similarity\n",
    "        \"\"\"\n",
    "        # Puts the similarity into a tuple with its playlist id\n",
    "        id_similarity = [\n",
    "            (id, similarity)\n",
    "            for id, similarity in enumerate(similarities)\n",
    "            if id != user_id and similarity > 0  # user_id is actually the user's playlist's id\n",
    "        ]\n",
    "        return sorted(id_similarity, key=lambda pair: pair[-1], reverse=True)\n",
    "\n",
    "    def suggest_name(self, similarities: List[Tuple[int, float]], length: int = 4) -> str:\n",
    "        \"\"\"Slaps together the top playlists' names first word and calls it a name\"\"\"\n",
    "        suggested_name = \"\"\n",
    "        for z in range(length):\n",
    "            # print(f\"Most similar playlist{[z]} name:\", self.playlist_names[similarities[z][0]])\n",
    "            suggested_name = \" \".join(\n",
    "                [suggested_name, self.playlist_names[similarities[z][0]].split(\" \")[0]]\n",
    "            )\n",
    "        return suggested_name.strip()\n",
    "\n",
    "    def user_based_suggestions(\n",
    "        self, similarities, max_suggestions: int = 10\n",
    "    ) -> Tuple[List[Tuple[str, float]], str]:\n",
    "        \"\"\"\n",
    "        Sorts the given similarities(playlist similarity scores),\n",
    "        gives each song a similarity score, and returns\n",
    "        the most similar songs & a suggested name for the playlist.\n",
    "        \"\"\"\n",
    "        suggestions: Dict[str, float] = defaultdict(float)\n",
    "        # Sort playlists into (playlist_id, similarity)\n",
    "        sorted_similarities = self.sort_similar_playlists(similarities, self.user_id)\n",
    "\n",
    "        suggested_name = self.suggest_name(sorted_similarities)\n",
    "\n",
    "        # Sum up the song similarities\n",
    "        for other_user_id, similarity in sorted_similarities:\n",
    "            for song in self.named_playlists[other_user_id]:\n",
    "                suggestions[song] += similarity\n",
    "\n",
    "        # Convert them to a sorted list\n",
    "        suggestions = sorted(suggestions.items(), key=lambda pair: pair[-1], reverse=True)\n",
    "\n",
    "        # Exclude the user_id's supplied songs\n",
    "        return [\n",
    "            (suggestion, weight)  # weight = summed up score from the playlists\n",
    "            for suggestion, weight in suggestions\n",
    "            if suggestion not in self.named_playlists[self.user_id]\n",
    "        ][:max_suggestions], suggested_name\n",
    "\n",
    "    def user_based_recommendation(\n",
    "        self, playlist: Union[dict, List[str]], limit: int = 10, user_id: int = -1\n",
    "    ) -> Tuple[List[Tuple[str, float]], str]:\n",
    "        \"\"\"Return a recommendation of tracks based off the given playlist(can be\n",
    "        mpd-formatted or list of strings)\"\"\"\n",
    "        self.user_id = user_id\n",
    "        similarities = self.compute_similarities(self.make_playlist_vector(playlist))\n",
    "        suggestions, name = self.user_based_suggestions(\n",
    "            similarities=similarities, max_suggestions=limit\n",
    "        )\n",
    "        return suggestions, name\n",
    "\n",
    "    def compute_song_similarities(self, song_id: int) -> List[float]:\n",
    "        \"\"\"Runs cosine_similarity on each song-playlists feature vector against the given song\"\"\"\n",
    "        return [\n",
    "            self.cosine_similarity(self.song_playlist_matrix[song_id], pl_vector_j)\n",
    "            for pl_vector_j in self.song_playlist_matrix\n",
    "        ]\n",
    "\n",
    "    def most_similar_songs_to(self, song_id: int) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Create a sorted list of the similar songs.\n",
    "        Each element in the returned list is a tuple of the songs's name and its cosine similarity\n",
    "        \"\"\"\n",
    "        similarities = self.compute_song_similarities(song_id)\n",
    "        song_similarity_pairs = [\n",
    "            (self.unique_songs[other_song_id], similarity)\n",
    "            for other_song_id, similarity in enumerate(similarities)\n",
    "            if song_id != other_song_id and similarity > 0\n",
    "        ]\n",
    "        return sorted(song_similarity_pairs, key=lambda pair: pair[-1], reverse=True)\n",
    "\n",
    "    def item_based_suggestions(\n",
    "        self, playlist_vector: List[int], max_suggestions: int = 10\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Goes through each song in the playlist vector and computes the most similar songs to that\n",
    "        song, then gives each song a similarity score, and returns the most similar songs.\n",
    "        The more frequently a computed similar song appears while going through each\n",
    "        song in the playlist, the higher its ranking will be.\n",
    "        \"\"\"\n",
    "        suggestions = defaultdict(float)\n",
    "\n",
    "        for song_id, in_playlist in enumerate(playlist_vector):\n",
    "            if in_playlist == 1:  # If song is in this playlist\n",
    "                similar_songs = self.most_similar_songs_to(song_id)  # Get most similar songs to it\n",
    "                # Add up the similarity score on each similar song\n",
    "                for song, similarity in similar_songs:\n",
    "                    suggestions[song] += similarity\n",
    "\n",
    "        suggestions = sorted(suggestions.items(), key=lambda pair: pair[-1], reverse=True)\n",
    "\n",
    "        return [\n",
    "            (suggestion, weight)\n",
    "            for suggestion, weight in suggestions\n",
    "            if suggestion not in self.named_playlists[self.user_id]  # Don't include existing songs\n",
    "        ][:max_suggestions]\n",
    "\n",
    "    def item_based_recommendation(\n",
    "        self, playlist: Union[dict, List[str]], limit: int = 10, user_id: int = -1\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Return a recommendation of tracks based off the given playlist(can be\n",
    "        mpd-formatted or list of strings)\"\"\"\n",
    "        t0 = time.time()\n",
    "        self.user_id = user_id\n",
    "        playlist_vector = self.make_playlist_vector(playlist)\n",
    "        suggestions = self.item_based_suggestions(\n",
    "            playlist_vector=playlist_vector, max_suggestions=limit\n",
    "        )\n",
    "        t1 = time.time()\n",
    "        print(f\"Time taken: {round(t1-t0, 2)} s\")\n",
    "        return suggestions\n",
    "\n",
    "    def summary(self):\n",
    "        total = 0\n",
    "        for playlist in self.playlists:\n",
    "            total += len(playlist)\n",
    "        print(\"- - - - Summary of data - - - -\")\n",
    "        print(\"Nr. of playlists:\", len(self.playlists))\n",
    "        print(\"Unique songs:\", len(self.unique_songs))\n",
    "        print(\"Average playlist length:\", total / len(self.playlists))\n",
    "        print(\"- - - - End of summary - - - - -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the recommender\n",
    "Load in one json and vectorize the playlists. If there's no pickle, it takes about 30 seconds on a ryzen 3800x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the found jsons: ['mpd.slice.26000-26999.json']\n",
      "Loaded 1 jsons\n",
      "Pickled data found.\n",
      "Found 34827 unique songs\n",
      "Time taken: 0.59 s\n",
      "playlist_vectors length: 1000\n"
     ]
    }
   ],
   "source": [
    "# Init recommender with path to the mpd json/s and if to use pickled vector data\n",
    "recommender = Collaborative_Recommender(\"mpd/data_samples\", rewrite_data=False)\n",
    "recommender.make_user_based_vectors()\n",
    "recommender.extract_playlist_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Sample tracks from playlist[69]:\n",
      "5 Seconds of Summer - Amnesia\n",
      "Christina Perri - A Thousand Years\n",
      "Miley Cyrus - Drive\n",
      "Ed Sheeran - Thinking Out Loud\n",
      "Justin Bieber - Down To Earth\n",
      "- - - - Summary of data - - - -\n",
      "Nr. of playlists: 1000\n",
      "Unique songs: 34827\n",
      "Average playlist length: 11.015\n",
      "- - - - End of summary - - - - -\n"
     ]
    }
   ],
   "source": [
    "print(\"5 Sample tracks from playlist[69]:\")\n",
    "recommender.sample_tracks(69, 5)\n",
    "recommender.make_item_based_vectors()\n",
    "recommender.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend songs to Jane\n",
    "\n",
    "Jane's playlist happens to be in the database already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jane's own playlist:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5 Seconds of Summer - Amnesia',\n",
       " 'Christina Perri - A Thousand Years',\n",
       " 'Miley Cyrus - Drive',\n",
       " 'Ed Sheeran - Thinking Out Loud',\n",
       " 'Justin Bieber - Down To Earth',\n",
       " 'Adele - Hello',\n",
       " 'Uncle Jed - Latch',\n",
       " 'Bon Iver - Skinny Love',\n",
       " 'Corey Gray - If I Lose Myself',\n",
       " 'Justin Bieber - Life Is Worth Living',\n",
       " 'X Ambassadors - Unsteady',\n",
       " 'Madilyn Bailey - Pompeii',\n",
       " 'Nicki Minaj - Bed Of Lies',\n",
       " 'Birdy - All You Never Say',\n",
       " 'Madilyn Bailey - Maps',\n",
       " 'Daya - Back to Me',\n",
       " 'Daya - Hide Away',\n",
       " 'Daya - Back to Me']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jane_id = 69\n",
    "print(\"Jane's own playlist:\")\n",
    "display(recommender.named_playlists[jane_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like a bunch of pop songs?\n",
    "- They seem to be relatively recent songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommendation(suggestions, name=None):\n",
    "    if(name is not None):\n",
    "        print(\"Suggested name:\", name)\n",
    "    \n",
    "    for i, s in enumerate(suggestions):\n",
    "        print(\"{0:<5}{1:<40} {2}\".format(f\"{i+1}.\", s[0], s[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User based recommendation\n",
    "The playlist can be in MPD format or just a list of strings. If the playlist is in the dataset then one can supply the id as to not be recommended your own songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested name: car you ❤️❤️ Syd\n",
      "1.   Ed Sheeran - Photograph                  0.8473668279740618\n",
      "2.   James Bay - Let It Go                    0.6311617785519165\n",
      "3.   Sam Smith - Lay Me Down                  0.6194777047540253\n",
      "4.   John Legend - All of Me                  0.6049336982536837\n",
      "5.   Passenger - Let Her Go                   0.5787191194277588\n",
      "6.   Jason Mraz - I Won't Give Up             0.5596744710984812\n",
      "7.   James Arthur - Say You Won't Let Go      0.5584253648693458\n",
      "8.   Sam Smith - I'm Not The Only One         0.5409875690857151\n",
      "9.   Sam Smith - Stay With Me                 0.5404209506202018\n",
      "10.  Lukas Graham - 7 Years                   0.5383299958530888\n",
      "11.  Meghan Trainor - Like I'm Gonna Lose You 0.5024478955016453\n",
      "12.  Justin Bieber - Love Yourself            0.4968716903397613\n"
     ]
    }
   ],
   "source": [
    "# Get jane's playlist\n",
    "janes_playlist = recommender.playlists[jane_id]\n",
    "# Run it through the recommender. Give it playlist, how many tracks, and own playlist id\n",
    "suggestions, sug_name = recommender.user_based_recommendation(janes_playlist, 12, jane_id)\n",
    "print_recommendation(suggestions, sug_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"car you ❤️❤️ Syd\" is a great playlist name!\n",
    "- We do seem to get a bunch of pop songs back.\n",
    "- Ed Sheeran & Justin Bieber are in Jane's playlist as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item based recommender\n",
    "Let's run Jane's playlist through the item based collaborative filter. Let us also test that a string list of his songs also works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 215.35 s\n",
      "Suggestions:\n",
      "1.   Ed Sheeran - Photograph                  1.5255518251563038\n",
      "2.   Passenger - Let Her Go                   1.4329548991977399\n",
      "3.   Sam Smith - I'm Not The Only One         1.4282577109497308\n",
      "4.   Joel Adams - Please Don't Go             1.3431411183876572\n",
      "5.   Sam Smith - Stay With Me                 1.3297328816157459\n",
      "6.   Shawn Mendes - Mercy                     1.3111933489642604\n",
      "7.   Jason Mraz - I Won't Give Up             1.3055642896400699\n",
      "8.   One Direction - History                  1.2983940880728837\n",
      "9.   Coldplay - Fix You                       1.2773365744229945\n",
      "10.  One Direction - If I Could Fly           1.2402517216602607\n",
      "11.  Birdy - Skinny Love                      1.2327594778960225\n",
      "12.  Adele - Someone Like You                 1.2165642728450732\n"
     ]
    }
   ],
   "source": [
    "janes_playlist = recommender.named_playlists[jane_id]\n",
    "suggestions = recommender.item_based_recommendation(janes_playlist, 12, jane_id)\n",
    "print(\"Suggestions:\")\n",
    "print_recommendation(suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again I can't tell if these are super similar because of my unfamiliarity. I'm sure I'd be happy!\n",
    "I know Adele's songs, let's see what is similar to hers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 12.61 s\n",
      "1.   Adele - Set Fire to the Rain             0.5\n",
      "2.   Adele - When We Were Young               0.49746833816309105\n",
      "3.   Adele - Rolling in the Deep              0.4216370213557839\n",
      "4.   Adele - Take It All                      0.408248290463863\n",
      "5.   Adele - One And Only                     0.3849001794597505\n"
     ]
    }
   ],
   "source": [
    "print_recommendation(recommender.item_based_recommendation(['Adele - Someone Like You'], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adele definitely is similar to Adele. I bet it's because people who like Adele also have loads of other of hers on their playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More samples with different playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first array printed is the user's 10 songs in the playlist, the other one are the recommendations and its last element is the suggested playlist name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rascal Flatts - What Hurts The Most',\n",
       " 'Hollywood Undead - Black Dahlia',\n",
       " 'Limp Bizkit - Behind Blue Eyes',\n",
       " 'Saliva - Always',\n",
       " 'Hollywood Undead - Pour Me',\n",
       " 'Hollywood Undead - S.C.A.V.A.',\n",
       " 'Hollywood Undead - Bullet',\n",
       " 'Hollywood Undead - Coming Back Down',\n",
       " 'Hollywood Undead - Mother Murder',\n",
       " 'Linkin Park - Waiting For The End']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested name: Country Three Outlaw Sleep\n",
      "1.   Drowning Pool - Bodies                   0.18036210542307424\n",
      "2.   Papa Roach - Last Resort                 0.1540163831377841\n",
      "3.   Rascal Flatts - Bless The Broken Road    0.1471111628412463\n",
      "4.   Brooks & Dunn - Red Dirt Road            0.14040176987488098\n",
      "5.   Three Days Grace - I Hate Everything About You 0.1386860985245757\n",
      "6.   Led Zeppelin - Stairway To Heaven        0.1296541708541989\n",
      "7.   Tim McGraw - Live Like You Were Dying    0.1286040998539846\n",
      "8.   Lonestar - My Front Porch Looking In     0.125112751243962\n",
      "9.   Kenny Chesney - There Goes My Life       0.12394252288475384\n",
      "10.  The Band Perry - If I Die Young          0.12025772997872064\n"
     ]
    }
   ],
   "source": [
    "id = 514\n",
    "display(recommender.named_playlists[id][:10])\n",
    "s, n = recommender.user_based_recommendation(playlist=recommender.playlists[id], user_id=id)\n",
    "print_recommendation(s, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The playlist is numetal and the recommendations are quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Duran Duran - Hungry Like The Wolf - 2009 Remastered Version',\n",
       " 'The Cars - Just What I Needed',\n",
       " 'a-ha - Take On Me',\n",
       " 'Madonna - Hung Up',\n",
       " 'Michael Jackson - Billie Jean',\n",
       " 'Depeche Mode - Enjoy The Silence - Single Mix',\n",
       " 'Loverboy - Working for the Weekend',\n",
       " 'The Apples - Hey Jude',\n",
       " 'Queen - Bohemian Rhapsody - Remastered 2011',\n",
       " 'The Police - Roxanne - Remastered 2003']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested name: the 80'S Blast Friday\n",
      "1.   Journey - Don't Stop Believin'           1.1616207136131862\n",
      "2.   Queen - Under Pressure - Remastered 2011 0.8802600169010343\n",
      "3.   Guns N' Roses - Sweet Child O' Mine      0.8185612962547691\n",
      "4.   Rick Springfield - Jessie's Girl         0.8090761593650391\n",
      "5.   The Police - Message In A Bottle - Remastered 2003 0.7900942818093478\n",
      "6.   The Outfield - Your Love                 0.7627315108430431\n",
      "7.   Eurythmics - Sweet Dreams (Are Made of This) - Remastered 0.727007894050679\n",
      "8.   Pat Benatar - Hit Me With Your Best Shot 0.6645785793798065\n",
      "9.   Simple Minds - Don't You (Forget About Me) 0.6622089780815504\n",
      "10.  The Police - Every Breath You Take - Remastered 2003 0.6478365997709965\n"
     ]
    }
   ],
   "source": [
    "id = 516\n",
    "display(recommender.named_playlists[id][:10])\n",
    "s, n = recommender.user_based_recommendation(playlist=recommender.playlists[id], user_id=id)\n",
    "print_recommendation(s, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! An 80's nostalgia playlist gets recommended more hits. The suggested name \"the 80'S Blast Friday\" is really good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The recommendations seem totally serviceable.\n",
    "\n",
    "But there's definitely a weakness to such a simple system. It will prefer to recommend the most popular songs out of all the other's playlists. Say you have a hiphop playlist, but most tracks are niche or older, then you will not be recommended such tracks because the recommender does addition on each playlist's tracks, say playlist[n] has similarity score of 0.05, then every song in that playlist gets incremented with that value. So the most popular and mainstream tracks will accrue more points. More recent and mainstream tracks will bubble up to the top, while the user's own niche will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
