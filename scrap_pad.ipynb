{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify MPD Collaborative Filtering\n",
    "- Idé: Rekommendera ett namn för givna spellistan genom att ge den samma namn som den närmaste playlisten.\n",
    "- Skapa en funktion som konverterar spellistorna att ha bara artisten och namnet i sig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "playlists = []\n",
    "DATA_PATH = \"mpd/data_samples\"\n",
    "REWRITE_DATA = False # Set to True to not use pickled vectors \n",
    "\n",
    "num_files = len(os.listdir(DATA_PATH))\n",
    "\n",
    "# Load in every json file from the mpd/data_samples directory\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    with open(os.path.join(DATA_PATH, filename), \"rt\", encoding=\"utf-8\") as f:\n",
    "        playlists.extend(json.load(f)[\"playlists\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jsons:  1\n",
      "Unique songs: 34250\n"
     ]
    }
   ],
   "source": [
    "unique_songs = sorted({f\"{song['artist_name']} - {song['track_name']}\"\n",
    "                           for playlist in playlists\n",
    "                           for i, song in enumerate(playlist[\"tracks\"])})\n",
    "print(\"Number of jsons: \", num_files)\n",
    "print(\"Unique songs:\", len(unique_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Civil Wars - From This Valley',\n",
       " 'Josh Garrels - Farther Along',\n",
       " 'Ethan Pierce - Dark Skies',\n",
       " 'Paramore - We Are Broken',\n",
       " \"Brandi Carlile - That Wasn't Me\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of the song names\n",
    "[f\"{s['artist_name']} - {s['track_name']}\" for i, s in enumerate(playlists[69][\"tracks\"][:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled data not found, generating vectors...\n",
      "Time taken: 292.45 s\n",
      "vectors length: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66666"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_playlist_vector(playlist: dict) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list of interests, produce a vector whose ith element is 1\n",
    "    if unique_interests[i] is in the list, 0 otherwise\n",
    "    \"\"\"\n",
    "    return [\n",
    "        1\n",
    "        if song\n",
    "        in [f\"{s['artist_name']} - {s['track_name']}\" for i, s in enumerate(playlist[\"tracks\"])]\n",
    "        else 0\n",
    "        for song in unique_songs #[:100] for testing\n",
    "    ]\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    if REWRITE_DATA:\n",
    "        print(\"Rewriting data: Generating vectors and dumping them\")\n",
    "        playlist_vectors = [make_playlist_vector(playlist) for playlist in playlists] # [:100] for testing\n",
    "        f = open(\"playlist_vectors.pickle\", \"wb\")\n",
    "        pickle.dump(playlist_vectors, f)\n",
    "    else:\n",
    "        f = open(\"playlist_vectors.pickle\", \"rb\")\n",
    "        print(\"Pickled data found.\")\n",
    "        playlist_vectors = pickle.load(f)\n",
    "except(FileNotFoundError):\n",
    "    print(\"Pickled data not found, generating vectors...\")\n",
    "    playlist_vectors = [make_playlist_vector(playlist) for playlist in playlists] # [:100] for testing\n",
    "    f = open(\"playlist_vectors.pickle\", \"wb\")\n",
    "    pickle.dump(playlist_vectors, f)\n",
    "finally:\n",
    "    f.close()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Time taken: {round(t1-t0, 2)} s\")\n",
    "print(\"vectors length:\", len(playlist_vectors))\n",
    "\n",
    "p = np.array(playlist_vectors)\n",
    "sum(p.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vector = List[float]\n",
    "pelles_interests = playlist_vectors[0]\n",
    "\n",
    "def dot(v: Vector, w: Vector) -> float:\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be same length\"\n",
    "\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def cosine_similarity(v1: Vector, v2: Vector) -> float:\n",
    "    return dot(v1, v2) / math.sqrt(dot(v1, v1) * dot(v2, v2))\n",
    "\n",
    "pelles_similarities = [cosine_similarity(pelles_interests, playlist_vector_i)\n",
    "                     for playlist_vector_i in playlist_vectors]\n",
    "\n",
    "# Users 0 and 9 share interests in Hadoop, Java, and Big Data \n",
    "#assert 0.56 < user_similarities[0][9] < 0.58, \"several shared interests\" \n",
    " \n",
    "# Users 0 and 8 share only one interest: Big Data \n",
    "#assert 0.18 < user_similarities[0][8] < 0.20, \"only one shared interest\"\n",
    "\n",
    "pelles_similarities[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity to playlists[0]:  1.0\n",
      "Similarity to playlists[38]:  0.15387460962256408\n",
      "Similarity to playlists[123]:  0.11774956564686527\n",
      "Similarity to playlists[225]:  0.10958925093990117\n",
      "Similarity to playlists[245]:  0.08964374649555988\n",
      "Similarity to playlists[262]:  0.23501778858208544\n",
      "Similarity to playlists[355]:  0.15062893357603013\n",
      "Similarity to playlists[359]:  0.09527699174583824\n",
      "Similarity to playlists[380]:  0.13509395646699554\n",
      "Similarity to playlists[663]:  0.1165103456070926\n",
      "Similarity to playlists[717]:  0.16840826742715195\n",
      "Similarity to playlists[721]:  0.15695698526580623\n",
      "Similarity to playlists[734]:  0.09061915769440536\n",
      "Similarity to playlists[747]:  0.1732981998492349\n",
      "Similarity to playlists[812]:  0.1190826279056167\n",
      "Similarity to playlists[844]:  0.0805716197153229\n",
      "Similarity to playlists[908]:  0.13464028341974354\n",
      "Similarity to playlists[944]:  0.1278274981412284\n"
     ]
    }
   ],
   "source": [
    "for i, sim in enumerate(pelles_similarities):\n",
    "    if (sim > 0.08):\n",
    "        print(f\"Similarity to playlists[{i}]: \", sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
